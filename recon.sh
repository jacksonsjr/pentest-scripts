#!/bin/bash

# my recon.sh

# Colours
red="\e[31m"
green="\e[32m"
yellow="\e[33m"
reset="\e[0m"

# Get date
date_recon=$(date +%Y%m%d)

# List of directories
pentest_dir=${HOME}/pentest
tools_dir=${pentest_dir}/tools
#wordlists_dir=${pentest_dir}/wordlists

# List of 3rd party binaries and python scripts to use in this script
amass_bin=$(command -v amass)
aquatone_bin=$(command -v aquatone)
dirsearch_bin=$(command -v dirsearch.py)
dnsrecon_bin=$(command -v dnsrecon.py)
dnssearch_bin=$(command -v dnssearch)
gobuster_bin=$(command -v gobuster)
httprobe_bin=$(command -v httprobe)
massdns_bin=$(command -v massdns)
sublist3r_bin=$(command -v sublist3r.py)
wayback_bin=$(command -v waybackurls)

# List of distribuition binaries to use in this script
jq_bin=$(command -v jq)
host_bin=$(command -v host)
nmap_bin=$(command -v nmap)
diff_bin=$(command -v diff)

# Get the correct path to use chromium with aquatone
for binary in /usr/bin/chromium /usr/bin/chromium-browser; do
    if  command -v ${binary} > /dev/null 2>&1 ; then
        chromium_bin=/usr/bin/chromium
    elif  command -v ${binary} > /dev/null 2>&1 ; then
        chromium_bin=/usr/bin/chromium-browser
    fi
done

# Verifying if all binaries there are in the system
if [[ -z ${amass_bin} ]] || [[ -z ${massdns_bin} ]] || [[ -z ${sublist3r_bin} ]] || \
    [[ -z ${httprobe_bin} ]] || [[ -z ${gobuster_bin} ]] || [[ -z ${dirsearch_bin} ]] || \
    [[ -z ${aquatone_bin} ]] || [[ -z ${chromium_bin} ]] || [[ -z ${dnsrecon_bin} ]] || \
    [[ -z ${dnssearch_bin} ]] || [[ -z ${wayback_bin} ]] || [[ -z ${jq_bin} ]] || \
    [[ -z ${host_bin} ]] || [[ -z ${nmap_bin} ]] || [[ -z ${diff_bin} ]] ; then
    echo -e "Please, ${yellow}make sure${reset} you got all tools (binaries and scripts)."
    exit 1
fi

# Tools parameters
aquatone_threads=5
dirsearch_threads=50
gobuster_threads=50
sublist3r_threads=40
resolver_dns="8.8.8.8"
web_extensions="php,asp,aspx,html,htmlx,shtml,txt"

# List of wordlists to use in this script
web_wordlists=("${tools_dir}"/dirsearch/db/dicc.txt)
dns_wordlists=()

if [ ${#web_wordlists[@]} -eq 0 ]; then
    echo -e "Please, ${yellow}make sure${reset} you have the default wordlists!"
    exit 1
fi

# Script usage description
usage(){
    (
    echo -e "Usage: ${yellow}$0 -d domain.com${reset}"
    echo "Options: "
    echo -e "\t-d    -  specify a valid domain [needed]"
    echo -e "\t-e    -  specify excluded subdomains after all treated files"
    echo -e "\t\t ${yellow}use -e domain1.com,domain2.com${reset}"
    echo -e "\t-r    -  specify the DNS to resolve"
    echo -e "\t\t ${yellow}use -r 1.1.1.1${reset}"
    echo -e "\t-b    -  if specified the Sublist3r will do brute force, this option take a long time to finish"
    echo -e "\t\t but it brings more results, you need to specify \"yes\" and any other value will be considered as \"no\""
    echo -e "\t\t ${yellow}use -b yes${reset}"
    echo -e "\t-s    -  specify the wordlist to put in dns_wordlist array and execute gobuster and dnssearch brute force"
    echo -e "\t\t this option take a long time to finish, use this own your need, by default the array is empty"
    echo -e "\t\t and not execute gobuster and dnssearch. The success of use those tools is a good wordlist."
    echo -e "\t\t ${yellow}use -s /path/to/wordlist1,/path/to/wordlist2${reset}"
    echo -e "\t-w    -  specity more wordlist to put in web_wordlist by default we use the ${tools_dir}/dirsearch/db/dicc.txt"
    echo -e "\t\t as the first wordlist to enumerate dirs and files from website."
    echo -e "\t\t ${yellow}use -w /path/to/wordlist1,/path/to/wordlist2${reset}"
    ) 1>&2; exit 1
}

# getopts is used by shell procedures to parse positional parameters.
while getopts ":d:e:r:b:s:w:" options; do
    case "${options}" in
        d)
            domain=${OPTARG}
            ;;
        e)
            set -f
	        IFS=","
            excluded+=("${OPTARG}")
	        unset IFS
            ;;
        r)
            unset resolver_dns
            resolver_dns="${OPTARG}"
            ;;
        b)
            brute_sublist3r=$(echo "${OPTARG}" | tr '[:upper:]' '[:lower:]')
            ;;
        s)
            set -f
            IFS=","
            dns_wordlists+=("${OPTARG}")
            unset IFS
            ;;
        w)
            set -f
            IFS=","
            web_wordlists+=("${OPTARG}")
            unset IFS
            ;;
        *)
            usage
            ;;
    esac
done
# OPTIND The index of the next argument to be processed by the getopts builtin command (see bash man page).
shift $((OPTIND - 1))

valid_domain=$(host -t A "${domain}" > /dev/null 2>&1; echo $?)

if [ -z "${domain}" ] || [ "${valid_domain}" -ne 0 ]; then
    usage
    exit 1
else
    # Create all dirs necessaries to report and recon 
    if [ -d ./"${domain}" ]; then
        echo "This is a known target." 
    fi
    echo -n "Preparing the directories structure to work... "
    mkdir -p ./"${domain}"/{log,recon_"${date_recon}"}
    log_dir="${domain}"/log
    recon_dir="${domain}"/recon_"${date_recon}"
    mkdir -p "${recon_dir}"/{tmp,report,wayback-data,aquatone,web-data}
    tmp_dir="${recon_dir}"/tmp
    report_dir="${recon_dir}"/report
    wayback_dir="${recon_dir}"/wayback-data
    aquatone_data="${recon_dir}"/aquatone
    web_data_dir=${recon_dir}/web-data
    echo "Done!"

    echo "./${domain}"
    echo -e "  ├── log (${yellow}log dir for recon.sh execution${reset})"
    echo -e "  └── $(echo "${recon_dir}" | awk -F "/" '{print $2}')"
    echo -e "      ├── aquatone (${yellow}aquatone output files${reset})"
    echo -e "      ├── report (${yellow}adjust function output files${reset})"
    echo -e "      ├── tmp (${yellow}subdomains recon tmp files${reset})"
    echo -e "      ├── wayback-data (${yellow}web data function for waybackurl output${reset})"
    echo -e "      └── web-data (${yellow}web data function for gobuster and dirsearch output${reset})"

    echo "Directories created."

    # Log
    execution_log="${log_dir}"/recon_log-"${date_recon}"
fi

message() {
    echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} ${red}Recon finished on${reset} ${yellow}${domain}${reset}${red}!${reset}"
    echo -e "\t ${red}Consider to use recon-ng and theHarvester to help get more assets!${reset}"
    echo -e "\t ${red}Use Shoda.io, Censys and others.${reset}"
}

subdomains_recon(){
    if [ -d "${tmp_dir}" ]; then
        echo -e "${red}Attention:${reset} The output from all tools used here will be placed in background and treated later."
        echo -e "\t   If you need look the output in execution time, you need to \"tail\" the files."
        echo -e "${green}Recon started on${reset} ${yellow}${domain}${reset}${green}!${reset}"
        echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Executing amass... "
        ${amass_bin} enum -d "${domain}" > "${tmp_dir}"/amass_output.txt 2>&1
        #${amass_bin} enum --passive -d "${domain}" > "${tmp_dir}"/amass_passive_output.txt 2>&1
        echo "Done!"

        if [ -n "${brute_sublist3r}" ] && [ "${brute_sublist3r}" == "yes" ]; then
            echo -e "${red}Warning:${reset} Sublist3r take almost 30 minutes to be executed!"
            echo -e "\t If you find yourself taking longer than expected: "
            echo -e "\t ${yellow}>>${reset} check for a zombie python process;"
            echo -e "\t ${yellow}>>${reset} stop the script;"
            echo -e "\t ${yellow}>>${reset} change the default parameters of the Sublist3r in the script to a lower value;"
            echo -e "\t ${yellow}>>${reset} execute the script again;"
            echo -e "\t ${yellow}>>${reset} if the problem persists, check your internet connection."
            echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Executing Sublist3r... "
            ${sublist3r_bin} -n -d "${domain}" -b -t ${sublist3r_threads} > "${tmp_dir}"/sublist3r_output.txt 2>&1
            echo "Done!"
        else
            echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Executing Sublist3r... "
            ${sublist3r_bin} -n -d "${domain}" > "${tmp_dir}"/sublist3r_output.txt 2>&1
            echo "Done!"
        fi

        echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Executing certspotter... "
        curl -s https://certspotter.com/api/v0/certs\?domain="${domain}" | jq '.[].dns_names[]' | \
            sed 's/\"//g' | sed 's/\*\.//g' | sort -u | grep "${domain}" >> "${tmp_dir}"/certspotter_output.txt
        echo "Done!"

        echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Executing crt.sh... "
        curl -s https://crt.sh/?q=%."${domain}"\&output=json | jq -r '.[].name_value' | \
            sed 's/\*\.//g' | sort -u >> "${tmp_dir}"/crtsh_output.txt
        echo "Done!"

        if [ ${#dns_wordlists[@]} -gt 0 ]; then
            echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} We will execute gobuster and dnssearch ${#dns_wordlists[@]} time(s)."
            for list in "${dns_wordlists[@]}"; do
                index=$(printf "%s\n" "${dns_wordlists[@]}" | grep -En "^${list}$" | awk -F":" '{print $1}')
                if [ -s "${list}" ]; then
                    echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Execution number ${index}... "
                    ${gobuster_bin} dns -z -q -r "${resolver_dns}" -t ${gobuster_threads} \
                        -d "${domain}" -w "${list}" > "${tmp_dir}"/gobuster_dns_output"${index}".txt 2>&1
                    ${dnssearch_bin} -consumers 600 -domain "${domain}" \
                        -wordlist "${list}" > "${tmp_dir}"/dnssearch_output"${index}".txt 2>&1
                    echo "Done!"
                else
                    echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Execution number ${index}, error: ${list} does not exist or is empty!"
                    continue
                fi
                unset index
            done
            unset list
            echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Execution of gobuster and dnssearch is done."
        fi
    else
        echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Make sure the directories structure was created. Stopping the script"
        exit 1
    fi
}

adjust_files(){
    if [ -d "${tmp_dir}" ] && [ -d "${report_dir}" ]; then
        echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Putting all domains only in one file and getting IPs block!!!"
        if [ -s "${tmp_dir}"/amass_output.txt ]; then
            echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Cleanning up the amass output... "
            grep -Ev "Starting.*names|Querying.*|Average.*performed" "${tmp_dir}"/amass_output.txt | \
                grep "${domain}" | sort -u >> "${tmp_dir}"/domains_tmp.txt
            grep -A 1000 "OWASP Amass.*OWASP/Amass" "${tmp_dir}"/amass_output.txt >> "${report_dir}"/amass_blocks_output.txt
            grep "Subdomain Name(s)" "${report_dir}"/amass_blocks_output.txt | awk '{print $1}' | \
                sed '/0.0.0.0\/0/d' >> "${report_dir}"/ips_blocks.txt
            echo "Done!"
        fi

        if [ -s "${tmp_dir}"/amass_passive_output.txt ]; then
            echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Cleanning up the amass passive output... "
            grep -Ev "Starting.*names|Querying.*|Average.*performed" "${tmp_dir}"/amass_passive_output.txt | \
                grep "${domain}" | sort -u >> "${tmp_dir}"/domains_tmp.txt
            echo "Done!"
        fi

        if [ -s "${tmp_dir}"/sublist3r_output.txt ]; then
            echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Cleanning up the sublist3r output... "
            sed -i -e 's/<BR>/\n/g' -e '1,10d' "${tmp_dir}"/sublist3r_output.txt 
            grep -Ev "Searching.*in|Starting.*subbrute|Total.*Found|Error:.*requests|Finished.*Enumeration|Warning:.*resolvers.txt"  \
                "${tmp_dir}"/sublist3r_output.txt | sort -u >> "${tmp_dir}"/domains_tmp.txt
            echo "Done!"
        fi

        if [ -s "${tmp_dir}"/certspotter_output.txt ]; then
            echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Cleanning up the certspotter output... " 
            sort -u "${tmp_dir}"/certspotter_output.txt >> "${tmp_dir}"/domains_tmp.txt
            echo "Done!"
        fi

        if [ -s "${tmp_dir}"/crtsh_output.txt ]; then
            echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Cleanning up the crtsh output... " 
            sort -u "${tmp_dir}"/crtsh_output.txt >> "${tmp_dir}"/domains_tmp.txt
            echo "Done!"
        fi

        while IFS= read -r file; do
            echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Cleanning up the gobuster dns output... "
            if [ -s "${file}" ]; then
                awk '{print $2}' "${file}" | tr '[:upper:]' '[:lower:]' | sort -u >> "${tmp_dir}"/domains_tmp.txt
            else
                echo " "
                echo -e "\t ${red}Error${reset}: file does not exist or is empty!"
                continue
            fi
            echo "Done!"
        done <<< "$(ls -1 "${tmp_dir}"/gobuster_dns_output*.txt > /dev/null 2>&1)"
        unset file

        while IFS= read -r file; do
            echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Cleanning up the dnsearch output... "
            if [ -s "${file}" ]; then
                awk '{print $2}' "${file}" | tr '[:upper:]' '[:lower:]' | sort -u >> "${tmp_dir}"/domains_tmp.txt
            else
                echo " "
                echo -e "\t ${red}Error${reset}: file does not exist or is empty!"
                continue
            fi
            echo "Done!"
        done <<< "$(ls -1 "${tmp_dir}"/dnssearch_output*.txt > /dev/null 2>&1)"
        unset file

        if [ -s "${tmp_dir}"/domains_tmp.txt ]; then
            echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Removing duplicated subdomains and unavailable domains... "
            if tr '[:upper:]' '[:lower:]' < "${tmp_dir}"/domains_tmp.txt | sed -e 's/^\.//' -e 's/^-//' | \
                sed -e 's/^http:\/\///' -e 's/^https:\/\///' | sort -u > "${report_dir}"/domains_all.txt ; then
                # Getting the domains that does not work
                while IFS= read -r subdomain; do
                    if host -t A "${subdomain}" | grep -E "NXDOMAIN|SERVFAIL" > /dev/null 2>&1 ; then
                        echo "${subdomain}" >> "${report_dir}"/domains_null.txt
                    fi
                done < "${report_dir}"/domains_all.txt
                unset subdomain
                # Remove domains that does not work and remove from domains_all.txt
                while IFS= read -r subdomain; do
                    if host -t A "${subdomain}" | grep -E "NXDOMAIN|SERVFAIL" > /dev/null 2>&1 ; then
                        sed -i "/^${subdomain}$/d" "${report_dir}"/domains_all.txt
                    fi
                done < "${report_dir}"/domains_null.txt
                unset subdomain
            else
                echo " "
                echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Error removing duplicated subdomains and unavailable domains!"
                exit 1
            fi     
            echo "Done!"
        else
            echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} The file with all domains from initial recon does not exist or is empty."
            echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Look all files from initial recon in ${tmp_dir} and fix the problem!"
            exit 1
        fi

        if [ ${#excluded[@]} -gt 0 ] && [ -s "${report_dir}"/domains_all.txt ]; then
            echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Excluding the subdomains from command line option... "
            for subdomain in "${excluded[@]}" ;do
                sed -i "/^${subdomain}$/d" "${report_dir}"/domains_all.txt
            done
            unset subdomain
            echo "Done!"
        fi
    else
        echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Make sure the directories structure was created. Stopping the script."
        exit 1
    fi
}

diff_domains(){
    if [ -d "${report_dir}" ]; then 
        if [ -s "${report_dir}"/domains_all.txt ]; then
            data=$(date +%Y%m%d) ; (( data-=1 ))
            #oldest_domains_file=$(find ./${domain} -name domains_all.* -type f -printf '%T+ %p\n' | sort -u | head -n 1 | awk '{print $2}')
            oldest_domains_file=$(find ./"${domain}" -name domains_all.txt -type f | sort -u | grep "${data}" | awk '{print $2}')
            if [[ -n "${oldest_domains_file}" ]]; then
                if cmp -s "${oldest_domains_file}" "${report_dir}"/domains_all.txt; then
                    echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Getting the difference between files to improve the time running recon.sh... "
                    diff -au "${oldest_domains_file}" "${report_dir}"/domains_all.txt | grep -E '^\+' | sed -e '/+++/d' -e 's/^+//' >> "${report_dir}"/domains_diff.txt
                    if [ -s "${report_dir}"/domains_diff.txt ]; then
                        if mv "${report_dir}"/domains_all.txt "${report_dir}"/domains_all."${date_recon}"; then
                            cp "${report_dir}"/domains_diff.txt "${report_dir}"/domains_all.txt
                        else
                            echo " "
                            echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Error during move domains_all.txt to domains_all.old."
                            echo -e "\t Stopping the script!"
                            exit 1
                        fi
                    else
                        echo " "
                        echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} There isn't any changes since last execution."
                        echo -e "\t Stopping the script!"
                        exit 1
                    fi
                    echo "Done!"
                else
                    echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} The files are same since last execution of recon.sh script!"
                    echo -e "\t Stopping the script!"
                    exit 1
                fi
            else
                echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} There isn't nothing in oldest_domains_file var, this the first execution of recon.sh script!"
            fi
            unset data
        else
            echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} diff_domains function error: file ${report_dir}/domains_all.txt does not exist or is empty!"
            exit 1
        fi
    else
        echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Make sure the directories structure was created. Stopping the script."
        exit 1
    fi
}

nmap_ips(){
    if [ -d "${report_dir}" ]; then
        if [ -s "${report_dir}"/domains_all.txt ]; then
            echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Getting subdomains IP to use with nmap... "
            while IFS= read -r subdomain; do
                host -t A "${subdomain}" | grep -Ev "NXDOMAIN|SERVFAIL" | \
                    grep "has address" | sort | awk '{print $1"\t"$4}' >> "${report_dir}"/domains_ips.txt
                host -t A "${subdomain}" | grep -Ev "NXDOMAIN|SERVFAIL" | \
                    grep "alias" | sort | awk '{print $1"\t"$6}' | sed -e 's/\.$//'>> "${report_dir}"/domains_aliases.txt
            done < "${report_dir}"/domains_all.txt
            awk '{print $2}' "${report_dir}"/domains_ips.txt | sort -u >> "${report_dir}"/nmap_ips.txt
            unset subdomain
            echo "Done!"
        else
            echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} nmap_ips function error: file ${report_dir}/domains_all.txt does not exist or is empty!"
            exit 1
        fi
    
        if [ -s "${report_dir}"/ips_blocks.txt ]; then
            echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Getting IPs from blocks with nmap -sn \"block\"... "
            count=0
            while IFS= read -r block; do
                block_file=nmap_$(echo "${block}" | sed -e 's/\//_/').txt
                cidr=$(echo "${block}" | awk -F'/' '{print $2}')
                if [[ ${cidr} -ge 21 ]]; then
                    nmap -sn "${block}" --exclude 10.0.0.0/8,172.16.0.0/12,192.168.0.0/16 --max-retries 3 --host-timeout 3 \
                        | grep -E "Nmap.*for" | awk '{print $6}' | sed -e 's/(//' -e 's/)//' > "${report_dir}"/"${block_file}"
                    sed -i '/^$/d' "${report_dir}"/"${block_file}"
                    (( count+=1 ))
                else
                    continue
                fi
                unset block_file
                unset cidr
            done < "${report_dir}"/ips_blocks.txt
            echo "Done!"
            if [[ ${count} -lt $(wc -l "${report_dir}"/ips_blocks.txt | awk '{print $1}') ]]; then
                echo -e "${red}Warning:${reset} Just ${count} block(s) were scanned, please look at ${report_dir}/ips_blocks.txt"
                echo -e "\t and nmap blocks files to know what were excluded blocks."
            fi
            unset count
        fi
    else
        echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Make sure the directories structure was created. Stopping the script."
        exit 1
    fi
}

hosts_alive(){
    if [ -d "${report_dir}" ]; then
        if [ -s "${report_dir}"/domains_all.txt ]; then
            echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Testing subdomains to know if it is or have web application... "
            while IFS= read -r subdomain; do
                echo "${subdomain}" | ${httprobe_bin} \
                    -p http:8080 -p http:8443 -p http:8081 -p http:8010 -p http:8085 -p http:8086 \
                    -p http:8087 -p http:8008 | sort -u >> "${report_dir}"/domains_web.txt 
            done < "${report_dir}"/domains_all.txt
            unset subdomain
            echo "Done!"

            if cp "${report_dir}"/domains_all.txt "${report_dir}"/domains_infra.txt; then
                echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Separating infrastructure from web application... "
                while IFS= read -r line; do
                    subdomain=$(echo "${line}" | sed -e "s/http:\/\///" -e "s/https:\/\///" -e "s/:*.i$//")
                    if  grep "${subdomain}" "${report_dir}"/domains_infra.txt > /dev/null 2>&1 ; then
                        sed -i "/^${subdomain}$/d" "${report_dir}"/domains_infra.txt
                    else
                        continue
                    fi
                    unset subdomain
                done < "${report_dir}"/domains_web.txt
                echo "Done!"
            fi
            if [ -s "${report_dir}"/domains_web.txt ] && [ -s "${report_dir}"/domains_infra.txt ]; then
                echo -e "\t We have $(wc -l "${report_dir}"/domains_web.txt | awk '{print $1}') Web Applications URLs."
                echo -e "\t We have $(wc -l "${report_dir}"/domains_infra.txt | awk '{print $1}') Infrastructure domains."
            fi
        else
            echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} hosts_alive function error: the ${report_dir}/domains_all.txt does not exist or is empty."
            exit 1
        fi
    else
        echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Make sure the directories structure was created. Stopping the script."
        exit 1
    fi
}

web_data(){
    if [ $# != 1 ]; then
        echo "Please, especify just 1 file to get URL from."
        exit 1
    else
        subdomain_file=$1
        if [ -d "${report_dir}" ] && [ -d "${wayback_dir}" ] && [ -d "${web_data_dir}" ]; then
            if [ ${#web_wordlists[@]} -gt 0 ] && [ -s "${subdomain_file}" ]; then
                echo -e "${red}Warning:${reset} It can take a long time to execute!"
                echo -e "\t We have ${#web_wordlists[@]} wordlists and $(wc -l "${report_dir}"/domains_web.txt | awk '{print $1}') urls to scan." 
                echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Web data function will use ${#web_wordlists[@]} wordlists with gobuster and dirsearch... "
                for list in "${web_wordlists[@]}"; do
                    index=$(printf "%s\n" "${web_wordlists[@]}" | grep -En "^""${list}""$" | awk -F":" '{print $1}')
                    if [ -s "${list}" ]; then
                        #wordlist_dir=$(dirname "${list}")
                        count=1
                        delay=2
                        while IFS= read -r subdomain; do
                            # Running a docker proxy instance to try bypass some protection system like WAF
                            #${docker_bin} run --name proxy-${index} --rm 
                            #proxy_ip=$(docker inspect --format '{{ .NetworkSettings.IPAddress }}' proxy-${index})
                            # Mounting the file names
                            file_gobuster=gobuster_$(echo "${subdomain}" | sed -e "s/http:\/\//http_/" -e "s/https:\/\//https_/" -e "s/:/_/" -e "s/\/$//" -e "s/\//_/" )_"${index}".txt
                            file_dirsearch=dirsearch_$(echo "${subdomain}" | sed -e "s/http:\/\//http_/" -e "s/https:\/\//https_/" -e "s/:/_/" -e "s/\/$//" -e "s/\//_/")_"${index}".txt
                            # Skipping the specific wordlist from dirsearch on gobuster
                            skip_list=$(grep -E "\.\%EXT\%|\.\%EX\%" "${list}" &>/dev/null; echo $?)
                            if [ "${skip_list}" -eq 0 ]; then
                                ${dirsearch_bin} -u "${subdomain}" -e ${web_extensions} -t ${dirsearch_threads} \
                                    --random-user-agents -w "${list}" --plain-text-report="${web_data_dir}"/"${file_dirsearch}" > /dev/null 2>&1 \
                                    # --proxy ${proxy_ip}:8118
                                unset file_dirsearch
                                unset subdomain
                                sleep ${delay}
                                (( count+=1 ))
                                (( delay+=2 ))
                            else
                                ${gobuster_bin} dir --delay 300ms -k -z -t ${gobuster_threads} -x ${web_extensions} -w "${list}" \
                                    -u "${subdomain}" > "${web_data_dir}"/"${file_gobuster}" 2>&1
                                sed -i "s/^..\[2K//" "${web_data_dir}"/"${file_gobuster}"
                                sleep ${count}
                                ${dirsearch_bin} -u "${subdomain}" -e ${web_extensions} -t ${dirsearch_threads} \
                                    --random-user-agents -w "${list}" --plain-text-report="${web_data_dir}"/"${file_dirsearch}" > /dev/null 2>&1 \
                                    # --proxy ${proxy_ip}:8118
                                unset file_dirsearch
                                unset file_gobuster
                                unset subdomain
                                sleep ${delay}
                                (( count+=1 ))
                                (( delay+=2 ))
                            fi
                        done < "${subdomain_file}"
                        unset count
                        unset delay
                        #unset wordlist_dir
                    else
                        echo " "
                        echo -e "\t ${red}Error:${reset} ${list} does not exist or is empty!"
                        continue
                    fi
                    unset index
                    unset list
                done
                echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Web data function is done!"
            else
                echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} dirseach/goboster web_data function error: array of wordlists is empty or ${subdomain_file} does not exist or is empty. Stopping the script"
                exit 1
            fi

            if [ -s "${subdomain_file}" ]; then
                echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Executing wayback... "
                while IFS= read -r subdomain; do
                    file=wayback_$(echo "${subdomain}" | sed -e "s/http:\/\//http_/" -e "s/https:\/\//https_/" -e "s/:/_/" -e "s/\/$//" -e "s/\//_/").txt
                    echo "${subdomain}" | ${wayback_bin} > "${wayback_dir}"/"${file}" 2>&1
                    unset file
                done < "${subdomain_file}"
                unset subdomain
                echo "Done!"
            else
                echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} wayback web_data function error: ${subdomain_file} does not exist or is empty. Stopping the script"
                exit 1
            fi
        else
            echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Make sure the directories structure was created. Stopping the script."
            exit 1
        fi
        unset subdomain_file
    fi
}

robots_txt(){
    echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Looking for new URLs on robots.txt... "
    while IFS= read -r file; do
        if [[ -s ${file} ]] && grep "robots.txt" "${file}" > /dev/null 2>&1 ; then
            target=$(grep -E "Target:|Url:" "${web_data_dir}"/"${file}" | sed -e 's/^\[+\] //' | awk '{print $2}' | sed -e 's/\/$//') 
            for url in $(curl -s "${target}"/robots.txt | grep -Ev "^User-agent" | sed -e "/^Disallow \/$/d" | awk '{print $2}'); do
                echo "${target}${url}" >> "${tmp_dir}"/robots_urls.txt
            done
            unset url
            unset urls
            unset target
        fi
        if [ -s "${tmp_dir}"/robots_urls.txt ]; then
            mv "${tmp_dir}"/robots_urls.txt "${report_dir}"/
        fi
    done <<< "$(ls -1 "${web_data_dir}"/*.txt)"
    echo "Done!"
}

aquatone_function(){
    echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Starting aquatone scan... "
    for file in ${report_dir}/domains_web.txt ${report_dir}/robots_urls.txt; do
        aquatone_log=${tmp_dir}/aquatone_$(basename "${file}" | awk -F'.' '{print $1}').log
        aquatone_files_dir=${aquatone_data}/$(basename "${file}" | awk -F'.' '{print $1}')
        if [ ! -d "${aquatone_files_dir}" ]; then
            if [[ $(mkdir -p "${aquatone_files_dir}") ]]; then
                ${aquatone_bin} -chrome-path ${chromium_bin} -out "${aquatone_files_dir}" -threads ${aquatone_threads} > "${aquatone_log}" 2>&1
            else
                echo " "
                echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Something got wrong, wasnt possible create directory ${aquatone_files_dir}."
                echo -e "\t Please, look what got wrong and run the script again. Stopping the script!"
                exit 1
            fi
        else
            ${aquatone_bin} -chrome-path ${chromium_bin} -out "${aquatone_files_dir}" -threads ${aquatone_threads} < "${file}" > "${aquatone_log}" 2>&1
        fi
    done
    unset aquatone_log
    unset aquatone_files_dir
    unset file
    echo "Done!"
}

#report(){
#   Falta criar a parte de report, página web, subir o server em python, etc...
#}

clean_up(){
    echo -n "Cleanning empty files... "
    echo "Done!"
    echo -n "Cleanning vars... "
    unset tmp_dir
    unset report_dir
    unset wayback_dir
    unset aquatone_data
    unset recon_dir
    unset date_recon
    unset excluded
    unset domain
    unset web_data_dir
    echo "Done!"
}

# Initiating the recon.sh script
(
subdomains_recon
adjust_files
diff_domains
nmap_ips
hosts_alive
web_data "${report_dir}"/domains_web.txt
#robots_txt
#web_data ${report_dir}/robots_urls.txt
#aquatone_function
#report
#clean_up
message
) 2>&1 | tee -a "${execution_log}"
